{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# DECLARATION\n<br>\n(1) I hereby agree to follow any and all assignment rules and procedures as stated in Canvas for this course, MATH2319.\n\n(2) In particular, I solemnly swear that I will not discuss/ have not discussed my assignment solutions with anyone in any way and the solutions I am submitting are my own personal work.\n\nFull Name: [Pranamya Korde]"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Question 1 : Data Preperation for Machine Learning "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Description :"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset contains 690 number of observation instances with 16 attribute which contain a class atrribute. This dataset contains number of nominal categorical variables with both binary and multivalue variables and Numerical feature variables.\n\nThe dataset contains almost 7-8% of missing values spreading across all the columns.Observations may have zero or many missing values.\n\nThe class distribution of the data is :\n\n+: 307 (44.5%)\n<br>\n-: 383 (55.5%)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Loading DataSet and Summary Statistics"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "we have downloaded the data file (crx.data) from https://archive.ics.uci.edu/ml/datasets/Credit+Approval and then uploaded it into Azure project to read it as a local file. we have used read_csv function from pandas library to read and load the data. \n\nAs there are no column names mentioned for the data in the dataset to protect the confidentiality, we provide column names as A1 to A16 for all the columns while reading the data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nattrnames = ['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','A15','A16']\ndf = pd.read_csv('./crx.data', sep = ',', header = None, names = attrnames)\ndf.head(5)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A13</th>\n      <th>A14</th>\n      <th>A15</th>\n      <th>A16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00202</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00043</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00280</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>00100</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>00120</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can check further details about the data as below : "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.shape",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "(690, 16)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above data consists of 690 rows with 15 descriptive features and 'A16' as a target feature(Class attribute)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.info()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 690 entries, 0 to 689\nData columns (total 16 columns):\nA1     690 non-null object\nA2     690 non-null object\nA3     690 non-null float64\nA4     690 non-null object\nA5     690 non-null object\nA6     690 non-null object\nA7     690 non-null object\nA8     690 non-null float64\nA9     690 non-null object\nA10    690 non-null object\nA11    690 non-null int64\nA12    690 non-null object\nA13    690 non-null object\nA14    690 non-null object\nA15    690 non-null int64\nA16    690 non-null object\ndtypes: float64(2), int64(2), object(12)\nmemory usage: 86.3+ KB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above information shows that, the data contains 4 numerical features and 12 Categorical feature along with the target feature."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To describe numerical and Categorical features differently we use describe method respectively as follows:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.describe(include = np.number).round(3)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A3</th>\n      <th>A8</th>\n      <th>A11</th>\n      <th>A15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.759</td>\n      <td>2.223</td>\n      <td>2.400</td>\n      <td>1017.386</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.978</td>\n      <td>3.347</td>\n      <td>4.863</td>\n      <td>5210.103</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000</td>\n      <td>0.165</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.750</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>5.000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.208</td>\n      <td>2.625</td>\n      <td>3.000</td>\n      <td>395.500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>28.000</td>\n      <td>28.500</td>\n      <td>67.000</td>\n      <td>100000.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "            A3       A8      A11         A15\ncount  690.000  690.000  690.000     690.000\nmean     4.759    2.223    2.400    1017.386\nstd      4.978    3.347    4.863    5210.103\nmin      0.000    0.000    0.000       0.000\n25%      1.000    0.165    0.000       0.000\n50%      2.750    1.000    0.000       5.000\n75%      7.208    2.625    3.000     395.500\nmax     28.000   28.500   67.000  100000.000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.describe(include = np.object).round(3)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A12</th>\n      <th>A13</th>\n      <th>A14</th>\n      <th>A16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3</td>\n      <td>350</td>\n      <td>4</td>\n      <td>4</td>\n      <td>15</td>\n      <td>10</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>171</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>b</td>\n      <td>?</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>t</td>\n      <td>f</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00000</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>468</td>\n      <td>12</td>\n      <td>519</td>\n      <td>519</td>\n      <td>137</td>\n      <td>399</td>\n      <td>361</td>\n      <td>395</td>\n      <td>374</td>\n      <td>625</td>\n      <td>132</td>\n      <td>383</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "         A1   A2   A4   A5   A6   A7   A9  A10  A12  A13    A14  A16\ncount   690  690  690  690  690  690  690  690  690  690    690  690\nunique    3  350    4    4   15   10    2    2    2    3    171    2\ntop       b    ?    u    g    c    v    t    f    f    g  00000    -\nfreq    468   12  519  519  137  399  361  395  374  625    132  383"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Checking for Missing Values"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As suggested in the data discription file crx.names, the dataset contain almost 7% of the missing values. We can check missing values by isna() function in the pandas library."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.isna().sum()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "A1     0\nA2     0\nA3     0\nA4     0\nA5     0\nA6     0\nA7     0\nA8     0\nA9     0\nA10    0\nA11    0\nA12    0\nA13    0\nA14    0\nA15    0\nA16    0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As we can see above, all the column contains 0 NaN values but sometimes missing values are replcaed with unusual values in the data like '?' or '9999' etc. So we have to look for those unusual values and set them to the missing values first. To do this, we check the unusual values in the categorical columns first and set them to the missing values."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "categorical_cols = df.columns[df.dtypes==object].tolist()\nfor col in categorical_cols :\n    print(df.loc[df[col]=='?',[col]].count())",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "A1    12\ndtype: int64\nA2    12\ndtype: int64\nA4    6\ndtype: int64\nA5    6\ndtype: int64\nA6    9\ndtype: int64\nA7    9\ndtype: int64\nA9    0\ndtype: int64\nA10    0\ndtype: int64\nA12    0\ndtype: int64\nA13    0\ndtype: int64\nA14    13\ndtype: int64\nA16    0\ndtype: int64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As we can see above, categorical features A1, A2, A4, A5, A6, A7 and A14 have missing values which are presented as '?'.  We can set all the unsual values which are observed as '?' with 'NaN' values mentioned in the numpy library. we can use simple replace function for it. we can check the null values again after setting unusual values with null(i.e. NaN)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = df.replace('?', np.NaN)\ndf.isna().sum()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "A1     12\nA2     12\nA3      0\nA4      6\nA5      6\nA6      9\nA7      9\nA8      0\nA9      0\nA10     0\nA11     0\nA12     0\nA13     0\nA14    13\nA15     0\nA16     0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see above that, now there are missing values present in those feature columns. we can check it with the same mentioned in the description file (crx.names) of the data file.\n<br>\nAs mentioned in the description of the data preperation we have to impute those missing values with the mode of the respective feature columns. We are using fillna() function mentioned in the pandas library for the imputation. After imputation we can see that the NaN values are imputed with the Mode values of their repspective columns and there are no missing values present in the dataset now."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for col in categorical_cols:\n    df[col].fillna(df[col].mode()[0], inplace = True)\ndf.isna().sum()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "A1     0\nA2     0\nA3     0\nA4     0\nA5     0\nA6     0\nA7     0\nA8     0\nA9     0\nA10    0\nA11    0\nA12    0\nA13    0\nA14    0\nA15    0\nA16    0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Encoding Categorical Features"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Prior to modelling, it is necessary to encode all the categorical features (Target as well as Descriptive) into a set of numerical features. We have to encode the target features explicitely by dropping it from rest of the dataset."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Encoding the Target Feature"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We remove target feature 'A16' from the dataframe df and rename it as 'Target'. we store rest of the data in the same data frame df."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Target = df['A16']\ndf = df.drop(columns=['A16'])\nTarget.value_counts()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "-    383\n+    307\nName: A16, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "While encoding this feature, we have to assign positive class with value 1 and negative with 0. we will use replace function for that purpose."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Target = Target.replace({'-': 0, '+': 1})\nTarget.value_counts()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "0    383\n1    307\nName: A16, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Encoding Categorical Descriptive Features"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see from the data that all the descriptive features appears to be nominal as there is no natural ordering present between the values of these features, hence, we have to perform one-hot-encoding for them.\n<br>\nAs mentioned explicitely in the problem, we have to descritize column 'A2' via equal frequency binning with 3 bins named \"low\", \"medium\", \"high\". and then we have to use integer encoding for this feature. we have to copy our dataframe into another dataframe to prevent the data loss in case."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_cat = df.copy()\ndf_cat['A2'] = df_cat['A2'].astype(np.float64) \ndf_cat['A2'] = pd.qcut(df_cat['A2'], q=3,labels=['low', 'medium', 'high'])\ndf_cat.head(5)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A13</th>\n      <th>A14</th>\n      <th>A15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>medium</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00202</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>high</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00043</td>\n      <td>560</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>medium</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00280</td>\n      <td>824</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>medium</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>00100</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>low</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>00120</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  A1      A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15\n0  b  medium  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0\n1  a    high  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560\n2  a  medium  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824\n3  b  medium  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3\n4  b     low  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see above that the values in the numerical descriptive feature 'A2' are populated in the three equal frequency bins namely \"low\", \"medium\" and \"high\". \n<br>\nThe next step is to encode them by using integer encoding technique. For this we need define a mapping between the levels and the integers using a dictionary."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "level_mapping = {'low':0, 'medium':1, 'high':2}\ndf_cat['A2'] = df_cat['A2'].replace(level_mapping)\ndf_cat.head(5)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A13</th>\n      <th>A14</th>\n      <th>A15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00202</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>2</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00043</td>\n      <td>560</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>1</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00280</td>\n      <td>824</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>1</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>00100</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>0</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>00120</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  A1  A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15\n0  b   1  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0\n1  a   2  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560\n2  a   1  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824\n3  b   1  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3\n4  b   0  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As we can see above the feature 'A2' is converted into a numeric feature with 3 levels due to integer encoding.\n<br>\nFurther more, for rest of the categorical features, we have to use one-hot-encoding technique. For that we have to define **q** dummy variables for a categorical descriptive variable with **q** levels. The exception here is that when a categorical descriptive feature has only two levels, we define a single dummy variable.\n<br>\nFor each two-level categorical variable,  we have to make \"drop_first\" option \"True\" . We are using get_dummies() function to perform one-hot-encoding here. \nFirst, we have to check the categorical variables in the dataframe df_cat."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "categorical_cols = df_cat.columns[df_cat.dtypes==object].tolist()\ncategorical_cols",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13', 'A14']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for col in categorical_cols:\n    n = len(df_cat[col].unique())\n    if (n == 2):\n        df_cat[col] = pd.get_dummies(df_cat[col], drop_first=True) ## for categorical features with 2 levels \n# for categorical features with >2 levels        \ndf_cat_encoded = pd.get_dummies(df_cat)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After encoding, the feature set has the following columns: "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_cat_encoded.columns",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "Index(['A1', 'A2', 'A3', 'A8', 'A9', 'A10', 'A11', 'A12', 'A15', 'A4_l',\n       ...\n       'A14_00640', 'A14_00680', 'A14_00711', 'A14_00720', 'A14_00760',\n       'A14_00840', 'A14_00928', 'A14_00980', 'A14_01160', 'A14_02000'],\n      dtype='object', length=211)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see that, all the columns are encoded into numeric values after one-hot-encoding. The number of features increases to 211 as for some features, multiple levels of unique feature values are present in the data."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Scaling of Features "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After encoding of the categorical values, we have to scale values of the descriptive features using standard scaling. Standard scaling process includes scaling by removing mean and then dividing by standard deviation of the respective feature column. After the scaling, each descriptive feature has mean of 0  and SD of 1.\n<br>\nFor this purpose we are using \"preprocessing\" module from the \"sklearn\" library."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import preprocessing\nData_scaler = preprocessing.StandardScaler()\ndf_cat_encoded_scaled = Data_scaler.fit_transform(df_cat_encoded)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After scaling is done, this process will convert our dataframe into numpy n dimensional array (numpy.ndarray).\n<br>\nAs the output of the scaler is ndarray object, all the column names are lost. so we have to convert this array again into data frame and assign previous data frames column names."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_cat_encoded_scaled_df = pd.DataFrame(df_cat_encoded_scaled, columns = df_cat_encoded.columns)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_clean = round(df_cat_encoded_scaled_df,3)",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_clean['target'] = Target",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_clean.shape",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "(690, 212)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_clean.describe(include = \"all\").round(3)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A15</th>\n      <th>A4_l</th>\n      <th>...</th>\n      <th>A14_00680</th>\n      <th>A14_00711</th>\n      <th>A14_00720</th>\n      <th>A14_00760</th>\n      <th>A14_00840</th>\n      <th>A14_00928</th>\n      <th>A14_00980</th>\n      <th>A14_01160</th>\n      <th>A14_02000</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>...</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n      <td>690.000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.000</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>-0.000</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.445</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>...</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>1.001</td>\n      <td>0.497</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.512</td>\n      <td>-1.215</td>\n      <td>-0.957</td>\n      <td>-0.665</td>\n      <td>-1.048</td>\n      <td>-0.864</td>\n      <td>-0.494</td>\n      <td>-0.919</td>\n      <td>-0.195</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.512</td>\n      <td>-1.215</td>\n      <td>-0.756</td>\n      <td>-0.616</td>\n      <td>-1.048</td>\n      <td>-0.864</td>\n      <td>-0.494</td>\n      <td>-0.919</td>\n      <td>-0.195</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.661</td>\n      <td>0.007</td>\n      <td>-0.404</td>\n      <td>-0.366</td>\n      <td>0.955</td>\n      <td>-0.864</td>\n      <td>-0.494</td>\n      <td>-0.919</td>\n      <td>-0.194</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.661</td>\n      <td>1.229</td>\n      <td>0.493</td>\n      <td>0.120</td>\n      <td>0.955</td>\n      <td>1.157</td>\n      <td>0.123</td>\n      <td>1.088</td>\n      <td>-0.119</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.661</td>\n      <td>1.229</td>\n      <td>4.672</td>\n      <td>7.858</td>\n      <td>0.955</td>\n      <td>1.157</td>\n      <td>13.294</td>\n      <td>1.088</td>\n      <td>19.012</td>\n      <td>18.547</td>\n      <td>...</td>\n      <td>26.249</td>\n      <td>26.249</td>\n      <td>18.547</td>\n      <td>26.249</td>\n      <td>26.249</td>\n      <td>26.249</td>\n      <td>26.249</td>\n      <td>26.249</td>\n      <td>26.249</td>\n      <td>1.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 212 columns</p>\n</div>",
            "text/plain": "            A1       A2       A3       A8       A9      A10      A11      A12  \\\ncount  690.000  690.000  690.000  690.000  690.000  690.000  690.000  690.000   \nmean    -0.000   -0.000    0.000    0.000   -0.000    0.000   -0.000    0.000   \nstd      1.001    1.001    1.001    1.001    1.001    1.001    1.001    1.001   \nmin     -1.512   -1.215   -0.957   -0.665   -1.048   -0.864   -0.494   -0.919   \n25%     -1.512   -1.215   -0.756   -0.616   -1.048   -0.864   -0.494   -0.919   \n50%      0.661    0.007   -0.404   -0.366    0.955   -0.864   -0.494   -0.919   \n75%      0.661    1.229    0.493    0.120    0.955    1.157    0.123    1.088   \nmax      0.661    1.229    4.672    7.858    0.955    1.157   13.294    1.088   \n\n           A15     A4_l   ...     A14_00680  A14_00711  A14_00720  A14_00760  \\\ncount  690.000  690.000   ...       690.000    690.000    690.000    690.000   \nmean     0.000   -0.000   ...         0.000      0.000     -0.000      0.000   \nstd      1.001    1.001   ...         1.001      1.001      1.001      1.001   \nmin     -0.195   -0.054   ...        -0.038     -0.038     -0.054     -0.038   \n25%     -0.195   -0.054   ...        -0.038     -0.038     -0.054     -0.038   \n50%     -0.194   -0.054   ...        -0.038     -0.038     -0.054     -0.038   \n75%     -0.119   -0.054   ...        -0.038     -0.038     -0.054     -0.038   \nmax     19.012   18.547   ...        26.249     26.249     18.547     26.249   \n\n       A14_00840  A14_00928  A14_00980  A14_01160  A14_02000   target  \ncount    690.000    690.000    690.000    690.000    690.000  690.000  \nmean       0.000      0.000      0.000      0.000      0.000    0.445  \nstd        1.001      1.001      1.001      1.001      1.001    0.497  \nmin       -0.038     -0.038     -0.038     -0.038     -0.038    0.000  \n25%       -0.038     -0.038     -0.038     -0.038     -0.038    0.000  \n50%       -0.038     -0.038     -0.038     -0.038     -0.038    0.000  \n75%       -0.038     -0.038     -0.038     -0.038     -0.038    1.000  \nmax       26.249     26.249     26.249     26.249     26.249    1.000  \n\n[8 rows x 212 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_clean.head(5)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A15</th>\n      <th>A4_l</th>\n      <th>...</th>\n      <th>A14_00680</th>\n      <th>A14_00711</th>\n      <th>A14_00720</th>\n      <th>A14_00760</th>\n      <th>A14_00840</th>\n      <th>A14_00928</th>\n      <th>A14_00980</th>\n      <th>A14_01160</th>\n      <th>A14_02000</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.661</td>\n      <td>0.007</td>\n      <td>-0.957</td>\n      <td>-0.291</td>\n      <td>0.955</td>\n      <td>1.157</td>\n      <td>-0.288</td>\n      <td>-0.919</td>\n      <td>-0.195</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.512</td>\n      <td>1.229</td>\n      <td>-0.060</td>\n      <td>0.244</td>\n      <td>0.955</td>\n      <td>1.157</td>\n      <td>0.741</td>\n      <td>-0.919</td>\n      <td>-0.088</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.512</td>\n      <td>0.007</td>\n      <td>-0.856</td>\n      <td>-0.216</td>\n      <td>0.955</td>\n      <td>-0.864</td>\n      <td>-0.494</td>\n      <td>-0.919</td>\n      <td>-0.037</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.661</td>\n      <td>0.007</td>\n      <td>-0.647</td>\n      <td>0.457</td>\n      <td>0.955</td>\n      <td>1.157</td>\n      <td>0.535</td>\n      <td>1.088</td>\n      <td>-0.195</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.661</td>\n      <td>-1.215</td>\n      <td>0.174</td>\n      <td>-0.154</td>\n      <td>0.955</td>\n      <td>-0.864</td>\n      <td>-0.494</td>\n      <td>-0.919</td>\n      <td>-0.195</td>\n      <td>-0.054</td>\n      <td>...</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.054</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>-0.038</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 212 columns</p>\n</div>",
            "text/plain": "      A1     A2     A3     A8     A9    A10    A11    A12    A15   A4_l  \\\n0  0.661  0.007 -0.957 -0.291  0.955  1.157 -0.288 -0.919 -0.195 -0.054   \n1 -1.512  1.229 -0.060  0.244  0.955  1.157  0.741 -0.919 -0.088 -0.054   \n2 -1.512  0.007 -0.856 -0.216  0.955 -0.864 -0.494 -0.919 -0.037 -0.054   \n3  0.661  0.007 -0.647  0.457  0.955  1.157  0.535  1.088 -0.195 -0.054   \n4  0.661 -1.215  0.174 -0.154  0.955 -0.864 -0.494 -0.919 -0.195 -0.054   \n\n    ...    A14_00680  A14_00711  A14_00720  A14_00760  A14_00840  A14_00928  \\\n0   ...       -0.038     -0.038     -0.054     -0.038     -0.038     -0.038   \n1   ...       -0.038     -0.038     -0.054     -0.038     -0.038     -0.038   \n2   ...       -0.038     -0.038     -0.054     -0.038     -0.038     -0.038   \n3   ...       -0.038     -0.038     -0.054     -0.038     -0.038     -0.038   \n4   ...       -0.038     -0.038     -0.054     -0.038     -0.038     -0.038   \n\n   A14_00980  A14_01160  A14_02000  target  \n0     -0.038     -0.038     -0.038       1  \n1     -0.038     -0.038     -0.038       1  \n2     -0.038     -0.038     -0.038       1  \n3     -0.038     -0.038     -0.038       1  \n4     -0.038     -0.038     -0.038       1  \n\n[5 rows x 212 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_clean.to_csv(\"df_clean.csv\", index =False)",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "***"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Question 2 : Examples on K-Nearest Neighbour Algorithm"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Question 1 :  What value would a 3-nearest neighbor prediction model using\nManhattan distance return for the CPI of Russia?**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We have to find out CPI value for Russia as explained in the problem using Manhattan Distance and with K = 3.\n<br>\nFirst we have read the data and load it into the python for further processing. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport math\n\ndf1= pd.read_csv(\"./Asignment1_Q2.csv\")# read the data from local file.\ndf = df1.copy() #Copy the same data into another dataframe as we are droping target row and column from this dataframe to find distances\ndf2 = df1.copy()\ndf.tail(5)",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_ID</th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n      <th>CPI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>Canada</td>\n      <td>80.99</td>\n      <td>24.79</td>\n      <td>4.9</td>\n      <td>1.42</td>\n      <td>14.2</td>\n      <td>8.6725</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Australia</td>\n      <td>82.09</td>\n      <td>25.40</td>\n      <td>4.2</td>\n      <td>1.86</td>\n      <td>11.5</td>\n      <td>8.8442</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sweden</td>\n      <td>81.43</td>\n      <td>22.18</td>\n      <td>2.4</td>\n      <td>1.27</td>\n      <td>12.8</td>\n      <td>9.2985</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>New Zealand</td>\n      <td>80.67</td>\n      <td>27.81</td>\n      <td>4.9</td>\n      <td>1.13</td>\n      <td>12.3</td>\n      <td>9.4627</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Russia</td>\n      <td>67.62</td>\n      <td>31.68</td>\n      <td>10.0</td>\n      <td>3.87</td>\n      <td>12.9</td>\n      <td>?</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     COUNTRY_ID  LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS  \\\n12       Canada     80.99         24.79          4.9       1.42          14.2   \n13    Australia     82.09         25.40          4.2       1.86          11.5   \n14       Sweden     81.43         22.18          2.4       1.27          12.8   \n15  New Zealand     80.67         27.81          4.9       1.13          12.3   \n16       Russia     67.62         31.68         10.0       3.87          12.9   \n\n       CPI  \n12  8.6725  \n13  8.8442  \n14  9.2985  \n15  9.4627  \n16       ?  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "CPI_Col = df.iloc[:,6]     # we save the column 'CPI' as it is a target feature column\nCPI_Col = CPI_Col.tolist()\ndf=df.drop('CPI',axis=1)  # we drop the target feature column.",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Country_Col = df.iloc[:,0]     #we save the column 'COUNTRY_ID' into another variable and convert it into List.\nCountry_Col = Country_Col.tolist()\ndf=df.drop('COUNTRY_ID',axis=1) # we drop the column 'COUNTRY_ID' from df dataframe as we need only numerical data to find distances.",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Pred_row = df.iloc[16,:]    # we save the last row of the data for which we have to predict the CPI into another variable and convert it into a list\nPred_row = Pred_row.tolist()\ndf=df.drop(16, axis = 0)  # we drop the last row as we need it to find distances.",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see below that after droping the target features and some irrelevant features, we got the dataset from which we can calculate the Manhattan distance of Russia from every other country."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.tail(5)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>80.24</td>\n      <td>22.07</td>\n      <td>3.5</td>\n      <td>1.31</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>80.99</td>\n      <td>24.79</td>\n      <td>4.9</td>\n      <td>1.42</td>\n      <td>14.2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>82.09</td>\n      <td>25.40</td>\n      <td>4.2</td>\n      <td>1.86</td>\n      <td>11.5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>81.43</td>\n      <td>22.18</td>\n      <td>2.4</td>\n      <td>1.27</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>80.67</td>\n      <td>27.81</td>\n      <td>4.9</td>\n      <td>1.13</td>\n      <td>12.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS\n11     80.24         22.07          3.5       1.31          12.0\n12     80.99         24.79          4.9       1.42          14.2\n13     82.09         25.40          4.2       1.86          11.5\n14     81.43         22.18          2.4       1.27          12.8\n15     80.67         27.81          4.9       1.13          12.3"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To calculate Manhattan Distances from Russia to every other country we need to convert the values into tuple and then take sum of the absolute distances of every feature values related to other countries. \n<br>\nBelow is the code to calculate Manhattan distances of every country from Russia."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This code to calculate Manhattan distance of Russia from every country in data frame df:\nPred_row = tuple(Pred_row)\ndistance_list = []\nfor i in range(0,16):\n    df_row = df.loc[i].tolist()\n    df_row = tuple(df_row)\n    distance = sum([abs(a-b)for a, b in zip(Pred_row,df_row)])\n    distance_list.append(distance)\n    \n# As we have similar copy of data in dataframe df2, we can add the list of distances to this copy as a new column \n# We name that column as 'DISTANCES'.\ndf2=df2.drop(16, axis = 0) # before joining the new column we have to drop the target row from the data frame.\ndf2['DISTANCES']= distance_list\ndf2.tail(5)",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_ID</th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n      <th>CPI</th>\n      <th>DISTANCES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>Germany</td>\n      <td>80.24</td>\n      <td>22.07</td>\n      <td>3.5</td>\n      <td>1.31</td>\n      <td>12.0</td>\n      <td>8.0461</td>\n      <td>32.19</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Canada</td>\n      <td>80.99</td>\n      <td>24.79</td>\n      <td>4.9</td>\n      <td>1.42</td>\n      <td>14.2</td>\n      <td>8.6725</td>\n      <td>29.11</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Australia</td>\n      <td>82.09</td>\n      <td>25.40</td>\n      <td>4.2</td>\n      <td>1.86</td>\n      <td>11.5</td>\n      <td>8.8442</td>\n      <td>29.96</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sweden</td>\n      <td>81.43</td>\n      <td>22.18</td>\n      <td>2.4</td>\n      <td>1.27</td>\n      <td>12.8</td>\n      <td>9.2985</td>\n      <td>33.61</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>New Zealand</td>\n      <td>80.67</td>\n      <td>27.81</td>\n      <td>4.9</td>\n      <td>1.13</td>\n      <td>12.3</td>\n      <td>9.4627</td>\n      <td>25.36</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     COUNTRY_ID  LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS  \\\n11      Germany     80.24         22.07          3.5       1.31          12.0   \n12       Canada     80.99         24.79          4.9       1.42          14.2   \n13    Australia     82.09         25.40          4.2       1.86          11.5   \n14       Sweden     81.43         22.18          2.4       1.27          12.8   \n15  New Zealand     80.67         27.81          4.9       1.13          12.3   \n\n       CPI  DISTANCES  \n11  8.0461      32.19  \n12  8.6725      29.11  \n13  8.8442      29.96  \n14  9.2985      33.61  \n15  9.4627      25.36  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The next step is to find 3 nearest neighbours according to the distances, for that we have to sort our data frame in ascending order and then reset the indices accordingly."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df2_sorted = df2.sort_values('DISTANCES')\ndf2_sorted = df2_sorted.reset_index(drop = True)\ndf2_sorted.head(5)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_ID</th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n      <th>CPI</th>\n      <th>DISTANCES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argentina</td>\n      <td>75.77</td>\n      <td>32.30</td>\n      <td>13.3</td>\n      <td>0.76</td>\n      <td>10.1</td>\n      <td>2.9961</td>\n      <td>17.98</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S.A</td>\n      <td>78.51</td>\n      <td>29.85</td>\n      <td>6.3</td>\n      <td>4.72</td>\n      <td>13.7</td>\n      <td>7.1357</td>\n      <td>18.07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>China</td>\n      <td>74.87</td>\n      <td>29.98</td>\n      <td>13.7</td>\n      <td>1.95</td>\n      <td>6.4</td>\n      <td>3.6356</td>\n      <td>21.07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U.K.</td>\n      <td>80.09</td>\n      <td>28.49</td>\n      <td>4.4</td>\n      <td>2.59</td>\n      <td>13.0</td>\n      <td>7.7751</td>\n      <td>22.64</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>New Zealand</td>\n      <td>80.67</td>\n      <td>27.81</td>\n      <td>4.9</td>\n      <td>1.13</td>\n      <td>12.3</td>\n      <td>9.4627</td>\n      <td>25.36</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    COUNTRY_ID  LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS  \\\n0    Argentina     75.77         32.30         13.3       0.76          10.1   \n1        U.S.A     78.51         29.85          6.3       4.72          13.7   \n2        China     74.87         29.98         13.7       1.95           6.4   \n3         U.K.     80.09         28.49          4.4       2.59          13.0   \n4  New Zealand     80.67         27.81          4.9       1.13          12.3   \n\n      CPI  DISTANCES  \n0  2.9961      17.98  \n1  7.1357      18.07  \n2  3.6356      21.07  \n3  7.7751      22.64  \n4  9.4627      25.36  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As we can see that, the 3 nearest neighbours to Russia are Argentina, USA and China according to the Manhattan distance calculations. So to predict the 'CPI' value of Russia, we have to take average of 'CPI's of these three countries. below is the code to take average."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df2_sorted['CPI']= pd.to_numeric(df2_sorted['CPI'])\nx= 0.0\nfor i in range (0,3):\n    x += df2_sorted.iloc[i,6]\nx = x/3\nx",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "4.589133333333334"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**The value of CPI value predicted is : 4.589133333333334**\n<br>\n***"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Question 2 : What value would a weighted k-NN prediction model return for the CPI\nof Russia? Use k “ 16 (i.e., the full dataset) and a weighting scheme of\nthe reciprocal of the squared Manhattan distance between the neighbor\nand the query.**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "we already have a dataframe (df2_sorted) for which we have all the manhattan distances from Russia to the respective country"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df2_sorted.head(5)",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_ID</th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n      <th>CPI</th>\n      <th>DISTANCES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argentina</td>\n      <td>75.77</td>\n      <td>32.30</td>\n      <td>13.3</td>\n      <td>0.76</td>\n      <td>10.1</td>\n      <td>2.9961</td>\n      <td>17.98</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S.A</td>\n      <td>78.51</td>\n      <td>29.85</td>\n      <td>6.3</td>\n      <td>4.72</td>\n      <td>13.7</td>\n      <td>7.1357</td>\n      <td>18.07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>China</td>\n      <td>74.87</td>\n      <td>29.98</td>\n      <td>13.7</td>\n      <td>1.95</td>\n      <td>6.4</td>\n      <td>3.6356</td>\n      <td>21.07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U.K.</td>\n      <td>80.09</td>\n      <td>28.49</td>\n      <td>4.4</td>\n      <td>2.59</td>\n      <td>13.0</td>\n      <td>7.7751</td>\n      <td>22.64</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>New Zealand</td>\n      <td>80.67</td>\n      <td>27.81</td>\n      <td>4.9</td>\n      <td>1.13</td>\n      <td>12.3</td>\n      <td>9.4627</td>\n      <td>25.36</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    COUNTRY_ID  LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS  \\\n0    Argentina     75.77         32.30         13.3       0.76          10.1   \n1        U.S.A     78.51         29.85          6.3       4.72          13.7   \n2        China     74.87         29.98         13.7       1.95           6.4   \n3         U.K.     80.09         28.49          4.4       2.59          13.0   \n4  New Zealand     80.67         27.81          4.9       1.13          12.3   \n\n      CPI  DISTANCES  \n0  2.9961      17.98  \n1  7.1357      18.07  \n2  3.6356      21.07  \n3  7.7751      22.64  \n4  9.4627      25.36  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As it is mentioned in the problem description that we have to predict 'CPI' with weighted KNN method we have to find weights for all the distances of each country. To find weights, we have to take distances in a list and then calculate the reciprocal of their squares."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Weights = df2_sorted['DISTANCES']\nWeights_list = 1/Weights**2\nWeights_list",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "0     0.003093\n1     0.003063\n2     0.002253\n3     0.001951\n4     0.001555\n5     0.001450\n6     0.001355\n7     0.001262\n8     0.001180\n9     0.001158\n10    0.001114\n11    0.000965\n12    0.000885\n13    0.000114\n14    0.000087\n15    0.000076\nName: DISTANCES, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As we have value of K as 16 i.e. all the Countries, we have to take summation of Weights of each country and that of product of CPI and respective weight. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Sum_Weights_list = round(sum(Weights_list),4) # Summation of weights of each country.\nSum_Weights_list",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "0.0216"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df2_sorted['CPI']= pd.to_numeric(df2_sorted['CPI'])\nCPI_list = df2_sorted['CPI']\nCPI_list\nCPI_WEIGHT_list = [a*b for a, b in zip(CPI_list, Weights_list)]\nSum_CPI_WEIGHT_list = round(sum(CPI_WEIGHT_list),4) # summation of product of weights of each country to their respective CPI value.\nSum_CPI_WEIGHT_list",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "0.132"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As we have value of K as 16, we can predict the 'CPI' value of Russia just by dividing the Sum of (CPI*Weights of each country) by sum of (Weights of each country)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "round(Sum_CPI_WEIGHT_list/Sum_Weights_list,2)",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "6.11"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**The value of CPI value predicted using weighted KNN with k =16 is: 6.11**\n<br>\n***"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Question 3 : The descriptive features in this dataset are of different types. For example,\nsome are percentages, others are measured in years, and others are\nmeasured in counts per 1,000. We should always consider normalizing\nour data, but it is particularly important to do this when the descriptive\nfeatures are measured in different units. What value would a 3-\nnearest neighbor prediction model using Manhattan distance return for\nthe CPI of Russia when the descriptive features have been normalized\nusing range normalization?**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can amke a new copy of our original data frame in df3. We are using standard value of range for this problem as High = 1 and Low  = 0.\n<br>\nThe first step to solve this problem is making the dataframe ready to ccaluculate Manhattan distances by droping some columns and the target row of Russia."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df3 = df1.copy()\ndf3_CPI = df3.iloc[:,6]\ndf3_COUNTRY = df3.iloc[:,0]\ndf3 = df3.drop(['CPI','COUNTRY_ID'], axis = 1)\ndf3",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>59.61</td>\n      <td>23.21</td>\n      <td>74.3</td>\n      <td>4.44</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45.00</td>\n      <td>47.67</td>\n      <td>73.1</td>\n      <td>0.09</td>\n      <td>3.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51.30</td>\n      <td>38.23</td>\n      <td>82.6</td>\n      <td>1.07</td>\n      <td>4.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70.48</td>\n      <td>26.58</td>\n      <td>19.6</td>\n      <td>1.86</td>\n      <td>5.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75.77</td>\n      <td>32.30</td>\n      <td>13.3</td>\n      <td>0.76</td>\n      <td>10.1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>74.87</td>\n      <td>29.98</td>\n      <td>13.7</td>\n      <td>1.95</td>\n      <td>6.4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>73.12</td>\n      <td>42.93</td>\n      <td>14.5</td>\n      <td>1.43</td>\n      <td>7.2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>81.30</td>\n      <td>28.80</td>\n      <td>3.6</td>\n      <td>6.77</td>\n      <td>12.5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>78.51</td>\n      <td>29.85</td>\n      <td>6.3</td>\n      <td>4.72</td>\n      <td>13.7</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>80.15</td>\n      <td>27.23</td>\n      <td>3.5</td>\n      <td>0.60</td>\n      <td>11.5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>80.09</td>\n      <td>28.49</td>\n      <td>4.4</td>\n      <td>2.59</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>80.24</td>\n      <td>22.07</td>\n      <td>3.5</td>\n      <td>1.31</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>80.99</td>\n      <td>24.79</td>\n      <td>4.9</td>\n      <td>1.42</td>\n      <td>14.2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>82.09</td>\n      <td>25.40</td>\n      <td>4.2</td>\n      <td>1.86</td>\n      <td>11.5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>81.43</td>\n      <td>22.18</td>\n      <td>2.4</td>\n      <td>1.27</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>80.67</td>\n      <td>27.81</td>\n      <td>4.9</td>\n      <td>1.13</td>\n      <td>12.3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>67.62</td>\n      <td>31.68</td>\n      <td>10.0</td>\n      <td>3.87</td>\n      <td>12.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS\n0      59.61         23.21         74.3       4.44           0.4\n1      45.00         47.67         73.1       0.09           3.4\n2      51.30         38.23         82.6       1.07           4.1\n3      70.48         26.58         19.6       1.86           5.3\n4      75.77         32.30         13.3       0.76          10.1\n5      74.87         29.98         13.7       1.95           6.4\n6      73.12         42.93         14.5       1.43           7.2\n7      81.30         28.80          3.6       6.77          12.5\n8      78.51         29.85          6.3       4.72          13.7\n9      80.15         27.23          3.5       0.60          11.5\n10     80.09         28.49          4.4       2.59          13.0\n11     80.24         22.07          3.5       1.31          12.0\n12     80.99         24.79          4.9       1.42          14.2\n13     82.09         25.40          4.2       1.86          11.5\n14     81.43         22.18          2.4       1.27          12.8\n15     80.67         27.81          4.9       1.13          12.3\n16     67.62         31.68         10.0       3.87          12.9"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The next step is to normalize all the data by using Range Normalization process. Range Normalization includes removing the Minimum value of a feature from a given value and then dividing it by range of that feature column.\nWe are standardizing the values of High and Low as 1 and 0 so the calue of (High - low)*low becomes 1."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df3_cols = df3.columns.tolist()\ndf4 = pd.DataFrame(columns = df3_cols)\nfor i in df3_cols :\n    df4[i]= (df3[i]-min(df3[i]))/(max(df3[i])-min(df3[i]))\ndf4",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.393907</td>\n      <td>0.044531</td>\n      <td>0.896509</td>\n      <td>0.651198</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.881546</td>\n      <td>0.000000</td>\n      <td>0.217391</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.169857</td>\n      <td>0.631250</td>\n      <td>1.000000</td>\n      <td>0.146707</td>\n      <td>0.268116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.686978</td>\n      <td>0.176172</td>\n      <td>0.214464</td>\n      <td>0.264970</td>\n      <td>0.355072</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.829604</td>\n      <td>0.399609</td>\n      <td>0.135910</td>\n      <td>0.100299</td>\n      <td>0.702899</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.805338</td>\n      <td>0.308984</td>\n      <td>0.140898</td>\n      <td>0.278443</td>\n      <td>0.434783</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.758156</td>\n      <td>0.814844</td>\n      <td>0.150873</td>\n      <td>0.200599</td>\n      <td>0.492754</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.978700</td>\n      <td>0.262891</td>\n      <td>0.014963</td>\n      <td>1.000000</td>\n      <td>0.876812</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.903478</td>\n      <td>0.303906</td>\n      <td>0.048628</td>\n      <td>0.693114</td>\n      <td>0.963768</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.947695</td>\n      <td>0.201563</td>\n      <td>0.013716</td>\n      <td>0.076347</td>\n      <td>0.804348</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.946077</td>\n      <td>0.250781</td>\n      <td>0.024938</td>\n      <td>0.374251</td>\n      <td>0.913043</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.950121</td>\n      <td>0.000000</td>\n      <td>0.013716</td>\n      <td>0.182635</td>\n      <td>0.840580</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.970342</td>\n      <td>0.106250</td>\n      <td>0.031172</td>\n      <td>0.199102</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.000000</td>\n      <td>0.130078</td>\n      <td>0.022444</td>\n      <td>0.264970</td>\n      <td>0.804348</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.982205</td>\n      <td>0.004297</td>\n      <td>0.000000</td>\n      <td>0.176647</td>\n      <td>0.898551</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.961715</td>\n      <td>0.224219</td>\n      <td>0.031172</td>\n      <td>0.155689</td>\n      <td>0.862319</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.609868</td>\n      <td>0.375391</td>\n      <td>0.094763</td>\n      <td>0.565868</td>\n      <td>0.905797</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS\n0   0.393907      0.044531     0.896509   0.651198      0.000000\n1   0.000000      1.000000     0.881546   0.000000      0.217391\n2   0.169857      0.631250     1.000000   0.146707      0.268116\n3   0.686978      0.176172     0.214464   0.264970      0.355072\n4   0.829604      0.399609     0.135910   0.100299      0.702899\n5   0.805338      0.308984     0.140898   0.278443      0.434783\n6   0.758156      0.814844     0.150873   0.200599      0.492754\n7   0.978700      0.262891     0.014963   1.000000      0.876812\n8   0.903478      0.303906     0.048628   0.693114      0.963768\n9   0.947695      0.201563     0.013716   0.076347      0.804348\n10  0.946077      0.250781     0.024938   0.374251      0.913043\n11  0.950121      0.000000     0.013716   0.182635      0.840580\n12  0.970342      0.106250     0.031172   0.199102      1.000000\n13  1.000000      0.130078     0.022444   0.264970      0.804348\n14  0.982205      0.004297     0.000000   0.176647      0.898551\n15  0.961715      0.224219     0.031172   0.155689      0.862319\n16  0.609868      0.375391     0.094763   0.565868      0.905797"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The next step is to normalize the target row with the same range normalization. and then we drop the target row after normalizing it from the data frame."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df4_Russia = df4.iloc[16,:].tolist()\ndf4 = df4.drop(16, axis = 0)\ndf4_Russia = [round(z,6)for z in df4_Russia]\ndf4_Russia",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "[0.609868, 0.375391, 0.094763, 0.565868, 0.905797]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To calculate Manhattan Distances from Russia to every other country we need to convert the values into tuple and then take sum of the absolute distances of every feature values related to other countries. \n<br>\nBelow is the code to calculate Manhattan distances of every country from Russia."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df4_Russia = tuple(df4_Russia)\ndistance_list = []\nfor i in range(0,16):\n    df_row = df4.loc[i].tolist()\n    df_row = tuple(df_row)\n    distance = sum([abs(a-b)for a, b in zip(df4_Russia,df_row)])\n    distance_list.append(distance)\n\ndf4['CPI']=df3_CPI\ndf4['COUNTRY_ID']= df3_COUNTRY\ndf4['DISTANCES']= distance_list\ndf4",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n      <th>CPI</th>\n      <th>COUNTRY_ID</th>\n      <th>DISTANCES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.393907</td>\n      <td>0.044531</td>\n      <td>0.896509</td>\n      <td>0.651198</td>\n      <td>0.000000</td>\n      <td>1.5171</td>\n      <td>Afghanistan</td>\n      <td>2.339693</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.881546</td>\n      <td>0.000000</td>\n      <td>0.217391</td>\n      <td>1.7999</td>\n      <td>Haiti</td>\n      <td>3.275534</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.169857</td>\n      <td>0.631250</td>\n      <td>1.000000</td>\n      <td>0.146707</td>\n      <td>0.268116</td>\n      <td>2.4493</td>\n      <td>Nigeria</td>\n      <td>2.657949</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.686978</td>\n      <td>0.176172</td>\n      <td>0.214464</td>\n      <td>0.264970</td>\n      <td>0.355072</td>\n      <td>2.8622</td>\n      <td>Egypt</td>\n      <td>1.247652</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.829604</td>\n      <td>0.399609</td>\n      <td>0.135910</td>\n      <td>0.100299</td>\n      <td>0.702899</td>\n      <td>2.9961</td>\n      <td>Argentina</td>\n      <td>0.953568</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.805338</td>\n      <td>0.308984</td>\n      <td>0.140898</td>\n      <td>0.278443</td>\n      <td>0.434783</td>\n      <td>3.6356</td>\n      <td>China</td>\n      <td>1.066451</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.758156</td>\n      <td>0.814844</td>\n      <td>0.150873</td>\n      <td>0.200599</td>\n      <td>0.492754</td>\n      <td>3.7741</td>\n      <td>Brazil</td>\n      <td>1.422163</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.978700</td>\n      <td>0.262891</td>\n      <td>0.014963</td>\n      <td>1.000000</td>\n      <td>0.876812</td>\n      <td>5.8069</td>\n      <td>Israel</td>\n      <td>1.024251</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.903478</td>\n      <td>0.303906</td>\n      <td>0.048628</td>\n      <td>0.693114</td>\n      <td>0.963768</td>\n      <td>7.1357</td>\n      <td>U.S.A</td>\n      <td>0.596446</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.947695</td>\n      <td>0.201563</td>\n      <td>0.013716</td>\n      <td>0.076347</td>\n      <td>0.804348</td>\n      <td>7.536</td>\n      <td>Ireland</td>\n      <td>1.183672</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.946077</td>\n      <td>0.250781</td>\n      <td>0.024938</td>\n      <td>0.374251</td>\n      <td>0.913043</td>\n      <td>7.7751</td>\n      <td>U.K.</td>\n      <td>0.729507</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.950121</td>\n      <td>0.000000</td>\n      <td>0.013716</td>\n      <td>0.182635</td>\n      <td>0.840580</td>\n      <td>8.0461</td>\n      <td>Germany</td>\n      <td>1.245142</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.970342</td>\n      <td>0.106250</td>\n      <td>0.031172</td>\n      <td>0.199102</td>\n      <td>1.000000</td>\n      <td>8.6725</td>\n      <td>Canada</td>\n      <td>1.154176</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.000000</td>\n      <td>0.130078</td>\n      <td>0.022444</td>\n      <td>0.264970</td>\n      <td>0.804348</td>\n      <td>8.8442</td>\n      <td>Australia</td>\n      <td>1.110111</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.982205</td>\n      <td>0.004297</td>\n      <td>0.000000</td>\n      <td>0.176647</td>\n      <td>0.898551</td>\n      <td>9.2985</td>\n      <td>Sweden</td>\n      <td>1.234662</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.961715</td>\n      <td>0.224219</td>\n      <td>0.031172</td>\n      <td>0.155689</td>\n      <td>0.862319</td>\n      <td>9.4627</td>\n      <td>New Zealand</td>\n      <td>1.020267</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS     CPI  \\\n0   0.393907      0.044531     0.896509   0.651198      0.000000  1.5171   \n1   0.000000      1.000000     0.881546   0.000000      0.217391  1.7999   \n2   0.169857      0.631250     1.000000   0.146707      0.268116  2.4493   \n3   0.686978      0.176172     0.214464   0.264970      0.355072  2.8622   \n4   0.829604      0.399609     0.135910   0.100299      0.702899  2.9961   \n5   0.805338      0.308984     0.140898   0.278443      0.434783  3.6356   \n6   0.758156      0.814844     0.150873   0.200599      0.492754  3.7741   \n7   0.978700      0.262891     0.014963   1.000000      0.876812  5.8069   \n8   0.903478      0.303906     0.048628   0.693114      0.963768  7.1357   \n9   0.947695      0.201563     0.013716   0.076347      0.804348   7.536   \n10  0.946077      0.250781     0.024938   0.374251      0.913043  7.7751   \n11  0.950121      0.000000     0.013716   0.182635      0.840580  8.0461   \n12  0.970342      0.106250     0.031172   0.199102      1.000000  8.6725   \n13  1.000000      0.130078     0.022444   0.264970      0.804348  8.8442   \n14  0.982205      0.004297     0.000000   0.176647      0.898551  9.2985   \n15  0.961715      0.224219     0.031172   0.155689      0.862319  9.4627   \n\n     COUNTRY_ID  DISTANCES  \n0   Afghanistan   2.339693  \n1         Haiti   3.275534  \n2       Nigeria   2.657949  \n3         Egypt   1.247652  \n4     Argentina   0.953568  \n5         China   1.066451  \n6        Brazil   1.422163  \n7        Israel   1.024251  \n8         U.S.A   0.596446  \n9       Ireland   1.183672  \n10         U.K.   0.729507  \n11      Germany   1.245142  \n12       Canada   1.154176  \n13    Australia   1.110111  \n14       Sweden   1.234662  \n15  New Zealand   1.020267  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After calculating the distance between Russia and every other country, the next step is to sort the dataframe according to the distances and shifting the \"COUNTRY_ID\" column to the first. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df4_sorted= df4.sort_values('DISTANCES')\ndf4_sorted = df4_sorted[['COUNTRY_ID']+[col for col in df4_sorted if col not in ['COUNTRY_ID']]]\ndf4_sorted= df4_sorted.reset_index(drop = True)\ndf4_sorted",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_ID</th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n      <th>CPI</th>\n      <th>DISTANCES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U.S.A</td>\n      <td>0.903478</td>\n      <td>0.303906</td>\n      <td>0.048628</td>\n      <td>0.693114</td>\n      <td>0.963768</td>\n      <td>7.1357</td>\n      <td>0.596446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.K.</td>\n      <td>0.946077</td>\n      <td>0.250781</td>\n      <td>0.024938</td>\n      <td>0.374251</td>\n      <td>0.913043</td>\n      <td>7.7751</td>\n      <td>0.729507</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Argentina</td>\n      <td>0.829604</td>\n      <td>0.399609</td>\n      <td>0.135910</td>\n      <td>0.100299</td>\n      <td>0.702899</td>\n      <td>2.9961</td>\n      <td>0.953568</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New Zealand</td>\n      <td>0.961715</td>\n      <td>0.224219</td>\n      <td>0.031172</td>\n      <td>0.155689</td>\n      <td>0.862319</td>\n      <td>9.4627</td>\n      <td>1.020267</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Israel</td>\n      <td>0.978700</td>\n      <td>0.262891</td>\n      <td>0.014963</td>\n      <td>1.000000</td>\n      <td>0.876812</td>\n      <td>5.8069</td>\n      <td>1.024251</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>China</td>\n      <td>0.805338</td>\n      <td>0.308984</td>\n      <td>0.140898</td>\n      <td>0.278443</td>\n      <td>0.434783</td>\n      <td>3.6356</td>\n      <td>1.066451</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Australia</td>\n      <td>1.000000</td>\n      <td>0.130078</td>\n      <td>0.022444</td>\n      <td>0.264970</td>\n      <td>0.804348</td>\n      <td>8.8442</td>\n      <td>1.110111</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Canada</td>\n      <td>0.970342</td>\n      <td>0.106250</td>\n      <td>0.031172</td>\n      <td>0.199102</td>\n      <td>1.000000</td>\n      <td>8.6725</td>\n      <td>1.154176</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Ireland</td>\n      <td>0.947695</td>\n      <td>0.201563</td>\n      <td>0.013716</td>\n      <td>0.076347</td>\n      <td>0.804348</td>\n      <td>7.536</td>\n      <td>1.183672</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sweden</td>\n      <td>0.982205</td>\n      <td>0.004297</td>\n      <td>0.000000</td>\n      <td>0.176647</td>\n      <td>0.898551</td>\n      <td>9.2985</td>\n      <td>1.234662</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Germany</td>\n      <td>0.950121</td>\n      <td>0.000000</td>\n      <td>0.013716</td>\n      <td>0.182635</td>\n      <td>0.840580</td>\n      <td>8.0461</td>\n      <td>1.245142</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Egypt</td>\n      <td>0.686978</td>\n      <td>0.176172</td>\n      <td>0.214464</td>\n      <td>0.264970</td>\n      <td>0.355072</td>\n      <td>2.8622</td>\n      <td>1.247652</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Brazil</td>\n      <td>0.758156</td>\n      <td>0.814844</td>\n      <td>0.150873</td>\n      <td>0.200599</td>\n      <td>0.492754</td>\n      <td>3.7741</td>\n      <td>1.422163</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Afghanistan</td>\n      <td>0.393907</td>\n      <td>0.044531</td>\n      <td>0.896509</td>\n      <td>0.651198</td>\n      <td>0.000000</td>\n      <td>1.5171</td>\n      <td>2.339693</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Nigeria</td>\n      <td>0.169857</td>\n      <td>0.631250</td>\n      <td>1.000000</td>\n      <td>0.146707</td>\n      <td>0.268116</td>\n      <td>2.4493</td>\n      <td>2.657949</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Haiti</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.881546</td>\n      <td>0.000000</td>\n      <td>0.217391</td>\n      <td>1.7999</td>\n      <td>3.275534</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     COUNTRY_ID  LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS  \\\n0         U.S.A  0.903478      0.303906     0.048628   0.693114      0.963768   \n1          U.K.  0.946077      0.250781     0.024938   0.374251      0.913043   \n2     Argentina  0.829604      0.399609     0.135910   0.100299      0.702899   \n3   New Zealand  0.961715      0.224219     0.031172   0.155689      0.862319   \n4        Israel  0.978700      0.262891     0.014963   1.000000      0.876812   \n5         China  0.805338      0.308984     0.140898   0.278443      0.434783   \n6     Australia  1.000000      0.130078     0.022444   0.264970      0.804348   \n7        Canada  0.970342      0.106250     0.031172   0.199102      1.000000   \n8       Ireland  0.947695      0.201563     0.013716   0.076347      0.804348   \n9        Sweden  0.982205      0.004297     0.000000   0.176647      0.898551   \n10      Germany  0.950121      0.000000     0.013716   0.182635      0.840580   \n11        Egypt  0.686978      0.176172     0.214464   0.264970      0.355072   \n12       Brazil  0.758156      0.814844     0.150873   0.200599      0.492754   \n13  Afghanistan  0.393907      0.044531     0.896509   0.651198      0.000000   \n14      Nigeria  0.169857      0.631250     1.000000   0.146707      0.268116   \n15        Haiti  0.000000      1.000000     0.881546   0.000000      0.217391   \n\n       CPI  DISTANCES  \n0   7.1357   0.596446  \n1   7.7751   0.729507  \n2   2.9961   0.953568  \n3   9.4627   1.020267  \n4   5.8069   1.024251  \n5   3.6356   1.066451  \n6   8.8442   1.110111  \n7   8.6725   1.154176  \n8    7.536   1.183672  \n9   9.2985   1.234662  \n10  8.0461   1.245142  \n11  2.8622   1.247652  \n12  3.7741   1.422163  \n13  1.5171   2.339693  \n14  2.4493   2.657949  \n15  1.7999   3.275534  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After sorting the data frame, to predict the the 'CPI' value of the target column Russia, we have to calculate the average of first 3 distances as value if K is 3. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df4_sorted['CPI']= pd.to_numeric(df4_sorted['CPI'])\nx= 0.0\nfor i in range (0,3):\n    x += df4_sorted.iloc[i,6]\nx = x/3\nx",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "5.968966666666667"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "**The value of CPI value predicted is : 5.968966666666667**\n<br>\n***"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Question 4 : What value would a weighted k-NN prediction model—with k “ 16\n(i.e., the full dataset) and using a weighting scheme of the reciprocal of\nthe squared Euclidean distance between the neighbor and the query—\nreturn for the CPI of Russia when it is applied to the range-normalized\ndata?**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To solve the above problem,  we already have a dataframe of the range normalized values of each feature column from our previous problem which is 'df4_sorted'. So, we are using the same dataframe to solve this problem."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df4_sorted.head(5)",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_ID</th>\n      <th>LIFE_EXP</th>\n      <th>TOP10_INCOME</th>\n      <th>INFANT_MORT</th>\n      <th>MIL_SPEND</th>\n      <th>SCHOOL_YEARS</th>\n      <th>CPI</th>\n      <th>DISTANCES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U.S.A</td>\n      <td>0.903478</td>\n      <td>0.303906</td>\n      <td>0.048628</td>\n      <td>0.693114</td>\n      <td>0.963768</td>\n      <td>7.1357</td>\n      <td>0.596446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.K.</td>\n      <td>0.946077</td>\n      <td>0.250781</td>\n      <td>0.024938</td>\n      <td>0.374251</td>\n      <td>0.913043</td>\n      <td>7.7751</td>\n      <td>0.729507</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Argentina</td>\n      <td>0.829604</td>\n      <td>0.399609</td>\n      <td>0.135910</td>\n      <td>0.100299</td>\n      <td>0.702899</td>\n      <td>2.9961</td>\n      <td>0.953568</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New Zealand</td>\n      <td>0.961715</td>\n      <td>0.224219</td>\n      <td>0.031172</td>\n      <td>0.155689</td>\n      <td>0.862319</td>\n      <td>9.4627</td>\n      <td>1.020267</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Israel</td>\n      <td>0.978700</td>\n      <td>0.262891</td>\n      <td>0.014963</td>\n      <td>1.000000</td>\n      <td>0.876812</td>\n      <td>5.8069</td>\n      <td>1.024251</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    COUNTRY_ID  LIFE_EXP  TOP10_INCOME  INFANT_MORT  MIL_SPEND  SCHOOL_YEARS  \\\n0        U.S.A  0.903478      0.303906     0.048628   0.693114      0.963768   \n1         U.K.  0.946077      0.250781     0.024938   0.374251      0.913043   \n2    Argentina  0.829604      0.399609     0.135910   0.100299      0.702899   \n3  New Zealand  0.961715      0.224219     0.031172   0.155689      0.862319   \n4       Israel  0.978700      0.262891     0.014963   1.000000      0.876812   \n\n      CPI  DISTANCES  \n0  7.1357   0.596446  \n1  7.7751   0.729507  \n2  2.9961   0.953568  \n3  9.4627   1.020267  \n4  5.8069   1.024251  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As it is mentioned in the problem description that we have to predict 'CPI' with weighted KNN method we have to find weights for all the distances of each country. To find weights, we have to take distances in a list and then calculate the reciprocal of their squares."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Weights = df4_sorted['DISTANCES']\nWeights_list = 1/Weights**2\nWeights_list",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "0     2.810978\n1     1.879061\n2     1.099756\n3     0.960665\n4     0.953208\n5     0.879262\n6     0.811460\n7     0.750682\n8     0.713735\n9     0.656000\n10    0.645004\n11    0.642411\n12    0.494426\n13    0.182676\n14    0.141549\n15    0.093204\nName: DISTANCES, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "For this problem, we have value of K as 16 so to predict the CPI value for Russia, we have to take sum of every product of CPI values to their respective weights and divide it by the summation of every weight calculated."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Sum_Weights_list = round(sum(Weights_list),4) # Summation of weights of each country.\nSum_Weights_list",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "13.7141"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df4_sorted['CPI']= pd.to_numeric(df4_sorted['CPI'])\nCPI_list = df4_sorted['CPI']\nCPI_list\nCPI_WEIGHT_list = [a*b for a, b in zip(CPI_list, Weights_list)]\nSum_CPI_WEIGHT_list = round(sum(CPI_WEIGHT_list),4) # summation of product of weights of each country to their respective CPI value.\nSum_CPI_WEIGHT_list",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "90.6371"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Last step is to take division of the total product of CPI values and respective weights to the summation of total weights for every country."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "round(Sum_CPI_WEIGHT_list/Sum_Weights_list,2)",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "6.61"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**The value of CPI value predicted using weighted KNN with k =16 and range normalization is: 6.61**\n<br>\n***"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Question 5 : The actual 2011 CPI for Russia was 2.4488. Which of the predictions made was the\nmost accurate? Why do you think this was?**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Answer: As we can see the above values, none of the values can predict the accurate CPI for Russia because of two main reasons. 1. As we are calculating the Manhattan distance between every feature column with that of the Russia, we know that Manhattan distance is not the shortest distance between two points but it was measured along the axes at right angles so it gives longer distances between two points. 2. So generally,  Manhattan distance generally works only if the points are arranged in the form of a grid and the problem which we are working on gives more priority to the distance between the points only along with the grids, but not the geometric distance."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "***"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}